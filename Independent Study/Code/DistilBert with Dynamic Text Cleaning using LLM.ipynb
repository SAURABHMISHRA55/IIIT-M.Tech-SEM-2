{"cells":[{"cell_type":"markdown","metadata":{},"source":["**Title:** DistilBERT with Dynamic Text Cleaning using LLM\n","\n","**Summary:**\n","This notebook extends the functionality of a DistilBERT model for text classification by incorporating dynamic text cleaning using Language Model Fine-Tuning. The primary goal is to enhance the robustness and effectiveness of the classification model by dynamically cleaning potentially offensive or harmful text inputs before prediction.\n","\n","**Key Features:**\n","1. **DistilBERT Model for Text Classification:** The notebook utilizes a DistilBERT (Distilled BERT) model for sequence classification. DistilBERT is a lightweight version of BERT that offers faster inference without compromising performance significantly.\n","\n","2. **Dynamic Text Cleaning with Language Model Fine-Tuning:** Similar to BERT, the notebook integrates OpenAI's Language Model Fine-Tuning (LLM) to dynamically clean potentially offensive or harmful text inputs before passing them to the DistilBERT model for classification. This ensures that the model receives sanitized inputs, improving its performance and reliability.\n","\n","3. **Real-Time Text Classification:** The implemented script allows users to interactively input text for classification. The integrated text cleaning ensures that even if the input contains offensive language or hate speech, the model provides predictions based on non-offensive versions of the input text.\n","\n","4. **Enhanced Speech Processing and Prediction:** The notebook demonstrates an iterative approach to text processing and prediction, where potentially offensive inputs are automatically sanitized before classification. This enhances the usability and safety of the model for real-world applications.\n","\n","**Usage:**\n","- Users can leverage this notebook to build and deploy text classification models with enhanced robustness against offensive or harmful content.\n","- The integrated real-time text classification script allows for on-the-fly analysis of text inputs, making it suitable for applications requiring live content moderation or analysis.\n","- The combination of DistilBERT for classification and LLM for dynamic text cleaning provides a comprehensive solution for processing user-generated content in various applications, including social media monitoring, online forums moderation, and content filtering."]},{"cell_type":"code","execution_count":12,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-05-11T10:55:37.315057Z","iopub.status.busy":"2024-05-11T10:55:37.314370Z","iopub.status.idle":"2024-05-11T10:55:37.321526Z","shell.execute_reply":"2024-05-11T10:55:37.320624Z","shell.execute_reply.started":"2024-05-11T10:55:37.315023Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Using device: cuda\n"]}],"source":["import re\n","import numpy as np\n","import pandas as pd\n","import torch\n","from torch.utils.data import DataLoader, Dataset\n","from transformers import DistilBertTokenizer, DistilBertForSequenceClassification, AdamW\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import classification_report, accuracy_score\n","from tqdm import tqdm\n","\n","# Check GPU availability\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(f'Using device: {device}')"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2024-05-11T10:55:43.619872Z","iopub.status.busy":"2024-05-11T10:55:43.619494Z","iopub.status.idle":"2024-05-11T10:55:43.628210Z","shell.execute_reply":"2024-05-11T10:55:43.627170Z","shell.execute_reply.started":"2024-05-11T10:55:43.619841Z"},"trusted":true},"outputs":[],"source":["emoticons = [':-)', ':)', '(:', '(-:', ':))', '((:', ':-D', ':D', 'X-D', 'XD', 'xD', 'xD', '<3', '3', ':*', ':-*', 'xP', 'XP', 'XP', 'Xp', ':-|', ':->', ':-<', '8-)', ':-P', ':-p', '=P', '=p', ':*)', '*-*', 'B-)', 'O.o', 'X-(', ')-X']\n","\n","def clean_text(text):\n","    text = text.lower()\n","    text = re.sub(r'https?://[^\\s]+', '', text)\n","    text = re.sub(r'@\\w+', '', text)\n","    text = re.sub(r'\\d+', '', text)\n","    for emoticon in emoticons:\n","        text = text.replace(emoticon, '')\n","    text = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", text)\n","    text = re.sub(r\"([?.!,¿])\", r\" \", text)\n","    text = re.sub(r'[\" \"]+', \" \", text)\n","    return text.strip()\n"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2024-05-11T10:55:46.694628Z","iopub.status.busy":"2024-05-11T10:55:46.693946Z","iopub.status.idle":"2024-05-11T10:55:47.523995Z","shell.execute_reply":"2024-05-11T10:55:47.523208Z","shell.execute_reply.started":"2024-05-11T10:55:46.694590Z"},"trusted":true},"outputs":[],"source":["# Load dataset\n","df = pd.read_csv('/kaggle/input/dataset/labeled_data.csv')\n","df['tweet'] = df['tweet'].apply(clean_text)\n","\n","# Split dataset\n","train_texts, temp_texts, train_labels, temp_labels = train_test_split(df['tweet'], df['class'], test_size=0.3, random_state=42)\n","val_texts, test_texts, val_labels, test_labels = train_test_split(temp_texts, temp_labels, test_size=0.5, random_state=42)\n"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2024-05-11T10:55:49.895791Z","iopub.status.busy":"2024-05-11T10:55:49.895037Z","iopub.status.idle":"2024-05-11T10:56:02.927255Z","shell.execute_reply":"2024-05-11T10:56:02.926223Z","shell.execute_reply.started":"2024-05-11T10:55:49.895758Z"},"trusted":true},"outputs":[],"source":["tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n","\n","train_encodings = tokenizer(train_texts.tolist(), truncation=True, padding=True, max_length=128)\n","test_encodings = tokenizer(test_texts.tolist(), truncation=True, padding=True, max_length=128)\n","val_encodings = tokenizer(val_texts.tolist(), truncation=True, padding=True, max_length=128)\n"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2024-05-11T10:56:05.582070Z","iopub.status.busy":"2024-05-11T10:56:05.581714Z","iopub.status.idle":"2024-05-11T10:56:05.589755Z","shell.execute_reply":"2024-05-11T10:56:05.588828Z","shell.execute_reply.started":"2024-05-11T10:56:05.582042Z"},"trusted":true},"outputs":[],"source":["# Dataset class\n","class TweetDataset(Dataset):\n","    def __init__(self, encodings, labels):\n","        self.encodings = encodings\n","        self.labels = labels\n","\n","    def __getitem__(self, idx):\n","        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n","        item['labels'] = torch.tensor(self.labels[idx])\n","        return item\n","\n","    def __len__(self):\n","        return len(self.labels)\n","\n","train_dataset = TweetDataset(train_encodings, train_labels.tolist())\n","test_dataset = TweetDataset(test_encodings, test_labels.tolist())\n","val_dataset = TweetDataset(val_encodings, val_labels.tolist())"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2024-05-11T10:56:08.719234Z","iopub.status.busy":"2024-05-11T10:56:08.718886Z","iopub.status.idle":"2024-05-11T10:56:08.739601Z","shell.execute_reply":"2024-05-11T10:56:08.738317Z","shell.execute_reply.started":"2024-05-11T10:56:08.719208Z"},"trusted":true},"outputs":[],"source":["batch_size = 32\n","\n","train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n","val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n","test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n"]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2024-05-11T10:56:11.034320Z","iopub.status.busy":"2024-05-11T10:56:11.033348Z","iopub.status.idle":"2024-05-11T10:56:11.503727Z","shell.execute_reply":"2024-05-11T10:56:11.502572Z","shell.execute_reply.started":"2024-05-11T10:56:11.034278Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/opt/conda/lib/python3.10/site-packages/transformers/optimization.py:457: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n"]}],"source":["# Model initialization\n","model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels=3)  # Adjust num_labels according to your classification problem\n","optimizer = AdamW(model.parameters(), lr=5e-6)\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","model.to(device)\n","\n","# Training function\n","def train(epoch):\n","    model.train()\n","    total_loss, total_accuracy = 0, 0\n","    for batch in tqdm(train_loader, desc=f\"Training Epoch {epoch}\"):\n","        optimizer.zero_grad()\n","        input_ids = batch['input_ids'].to(device)\n","        attention_mask = batch['attention_mask'].to(device)\n","        labels = batch['labels'].to(device)\n","        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n","        loss = outputs.loss\n","        loss.backward()\n","        optimizer.step()\n","        \n","        total_loss += loss.item()\n","        logits = outputs.logits.detach().cpu().numpy()\n","        predictions = np.argmax(logits, axis=-1)\n","        total_accuracy += accuracy_score(labels.cpu().numpy(), predictions)\n","    \n","    avg_loss = total_loss / len(train_loader)\n","    avg_accuracy = total_accuracy / len(train_loader)\n","    print(f\"Training Loss: {avg_loss:.3f}\")\n","    print(f\"Training Accuracy: {avg_accuracy:.3f}\")"]},{"cell_type":"code","execution_count":20,"metadata":{"execution":{"iopub.execute_input":"2024-05-11T10:56:18.706902Z","iopub.status.busy":"2024-05-11T10:56:18.706539Z","iopub.status.idle":"2024-05-11T10:56:18.718786Z","shell.execute_reply":"2024-05-11T10:56:18.717673Z","shell.execute_reply.started":"2024-05-11T10:56:18.706873Z"},"trusted":true},"outputs":[],"source":["# Evaluation function\n","def evaluate(loader, desc=\"Evaluating\"):\n","    model.eval()\n","    total_loss, total_accuracy = 0, 0\n","    all_predictions, all_labels = [], []\n","    \n","    for batch in tqdm(loader, desc=desc):\n","        input_ids = batch['input_ids'].to(device)\n","        attention_mask = batch['attention_mask'].to(device)\n","        labels = batch['labels'].to(device)\n","        with torch.no_grad():\n","            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n","        \n","        loss = outputs.loss.item()\n","        total_loss += loss\n","        logits = outputs.logits.detach().cpu().numpy()\n","        predictions = np.argmax(logits, axis=-1)\n","        total_accuracy += accuracy_score(labels.cpu().numpy(), predictions)\n","        \n","        all_predictions.extend(predictions)\n","        all_labels.extend(labels.cpu().numpy())\n","\n","    avg_loss = total_loss / len(loader)\n","    avg_accuracy = total_accuracy / len(loader)\n","    print(f\"Validation Loss: {avg_loss:.3f}\")\n","    print(f\"Validation Accuracy: {avg_accuracy:.3f}\")\n","    \n","    return all_labels, all_predictions"]},{"cell_type":"code","execution_count":21,"metadata":{"execution":{"iopub.execute_input":"2024-05-11T10:56:21.346855Z","iopub.status.busy":"2024-05-11T10:56:21.346512Z","iopub.status.idle":"2024-05-11T10:58:56.075192Z","shell.execute_reply":"2024-05-11T10:58:56.074234Z","shell.execute_reply.started":"2024-05-11T10:56:21.346828Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Training Epoch 1: 100%|██████████| 543/543 [00:47<00:00, 11.49it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Training Loss: 0.408\n","Training Accuracy: 0.860\n"]},{"name":"stderr","output_type":"stream","text":["Evaluating: 100%|██████████| 117/117 [00:03<00:00, 35.95it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Validation Loss: 0.291\n","Validation Accuracy: 0.899\n"]},{"name":"stderr","output_type":"stream","text":["Training Epoch 2: 100%|██████████| 543/543 [00:47<00:00, 11.50it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Training Loss: 0.249\n","Training Accuracy: 0.913\n"]},{"name":"stderr","output_type":"stream","text":["Evaluating: 100%|██████████| 117/117 [00:03<00:00, 35.64it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Validation Loss: 0.255\n","Validation Accuracy: 0.913\n"]},{"name":"stderr","output_type":"stream","text":["Training Epoch 3: 100%|██████████| 543/543 [00:47<00:00, 11.49it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Training Loss: 0.221\n","Training Accuracy: 0.923\n"]},{"name":"stderr","output_type":"stream","text":["Evaluating: 100%|██████████| 117/117 [00:03<00:00, 36.08it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Validation Loss: 0.245\n","Validation Accuracy: 0.915\n"]},{"name":"stderr","output_type":"stream","text":["Final Test Evaluation: 100%|██████████| 117/117 [00:03<00:00, 36.93it/s]"]},{"name":"stdout","output_type":"stream","text":["Validation Loss: 0.233\n","Validation Accuracy: 0.914\n","                    precision    recall  f1-score   support\n","\n","       Hate Speech       0.51      0.23      0.32       207\n","Offensive Language       0.93      0.96      0.95      2880\n","           Neither       0.88      0.91      0.89       631\n","\n","          accuracy                           0.91      3718\n","         macro avg       0.77      0.70      0.72      3718\n","      weighted avg       0.90      0.91      0.90      3718\n","\n","Test Accuracy: 0.913\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["# Main training loop\n","for epoch in range(1, 4):\n","    train(epoch)\n","    evaluate(val_loader)\n","\n","# Final evaluation on test set\n","labels, predictions = evaluate(test_loader, \"Final Test Evaluation\")\n","print(classification_report(labels, predictions, target_names=['Hate Speech', 'Offensive Language', 'Neither']))\n","\n","# Accuracy\n","accuracy = accuracy_score(labels, predictions)\n","print(f\"Test Accuracy: {accuracy:.3f}\")"]},{"cell_type":"code","execution_count":22,"metadata":{"execution":{"iopub.execute_input":"2024-05-11T10:59:21.822162Z","iopub.status.busy":"2024-05-11T10:59:21.821434Z","iopub.status.idle":"2024-05-11T10:59:21.875389Z","shell.execute_reply":"2024-05-11T10:59:21.874484Z","shell.execute_reply.started":"2024-05-11T10:59:21.822110Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Number of hate speech comments: 1430\n","Examples of hate speech comments:\n","                                                 tweet\n","85   \"@Blackman38Tide: @WhaleLookyHere @HowdyDowdy1...\n","89   \"@CB_Baby24: @white_thunduh alsarabsss\" hes a ...\n","110  \"@DevilGrimz: @VigxRArts you're fucking gay, b...\n","184  \"@MarkRoundtreeJr: LMFAOOOO I HATE BLACK PEOPL...\n","202  \"@NoChillPaz: \"At least I'm not a nigger\" http...\n"]}],"source":["import pandas as pd\n","\n","# Load the dataset (replace 'path_to_your_dataset.csv' with your actual dataset path)\n","df = pd.read_csv('/kaggle/input/dataset/labeled_data.csv')\n","\n","# Filter the dataset for hate speech comments\n","hate_speech_comments = df[df['class'] == 0]\n","\n","# Display the hate speech comments\n","print(\"Number of hate speech comments:\", hate_speech_comments.shape[0])\n","print(\"Examples of hate speech comments:\")\n","print(hate_speech_comments[['tweet']].head())  # Display the first few comments\n"]},{"cell_type":"markdown","metadata":{},"source":["## Real-Time Text Classification Script\n","\n","This Python script is designed to classify text inputs in real-time, making it an invaluable tool for monitoring and analyzing user-generated content live. It can identify if the text is hate speech, offensive language, or neither.\n","\n","### Script Overview\n","\n","The script engages with the user in an interactive session where it continuously accepts text inputs. Each input is processed to determine its classification based on predefined categories: Hate Speech, Offensive Language, or Neither. This is particularly useful for applications that require live moderation or instant text analysis.\n","\n","### Code Functionality\n","\n","- **Text Cleaning**: Initially, the text provided by the user is cleaned to remove any unwanted characters or formatting.\n","- **Text Tokenization and Encoding**: The cleaned text is tokenized and encoded using a pre-configured tokenizer and model setup.\n","- **Model Prediction**: The tokenized text is fed into a neural network model, which evaluates the text and produces a prediction.\n","- **Classification**: The output from the model is interpreted as one of the three categories based on the highest probability.\n","- **Confidence Scores**: Alongside the classification, the script also outputs the confidence scores for each category, providing insight into the model's decision-making process.\n"]},{"cell_type":"code","execution_count":23,"metadata":{"execution":{"iopub.execute_input":"2024-05-11T10:59:24.743439Z","iopub.status.busy":"2024-05-11T10:59:24.743068Z","iopub.status.idle":"2024-05-11T11:00:32.357143Z","shell.execute_reply":"2024-05-11T11:00:32.356371Z","shell.execute_reply.started":"2024-05-11T10:59:24.743411Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Enter a tweet to analyze (or type 'exit' to quit):  I really do hate you\n"]},{"name":"stdout","output_type":"stream","text":["Predicted label: Neither\n","Confidence Scores: [0.03413306921720505, 0.135234072804451, 0.8306328654289246]\n"]},{"name":"stdout","output_type":"stream","text":["Enter a tweet to analyze (or type 'exit' to quit):  you are worthless idiot person\n"]},{"name":"stdout","output_type":"stream","text":["Predicted label: Offensive Language\n","Confidence Scores: [0.3015950620174408, 0.5868861675262451, 0.11151880770921707]\n"]},{"name":"stdout","output_type":"stream","text":["Enter a tweet to analyze (or type 'exit' to quit):  I dont like you\n"]},{"name":"stdout","output_type":"stream","text":["Predicted label: Neither\n","Confidence Scores: [0.049357328563928604, 0.1588636189699173, 0.7917789816856384]\n"]},{"name":"stdout","output_type":"stream","text":["Enter a tweet to analyze (or type 'exit' to quit):  exit\n"]}],"source":["def preprocess_and_predict(text):\n","    # Clean the text\n","    cleaned_text = clean_text(text)\n","\n","    # Tokenize the text\n","    encodings = tokenizer(cleaned_text, truncation=True, padding=True, max_length=128, return_tensors=\"pt\")\n","\n","    # Move tensors to the same device as model\n","    encodings = {key: val.to(device) for key, val in encodings.items()}\n","\n","    # Evaluation mode\n","    model.eval()\n","\n","    # Forward pass, no need to compute gradients\n","    with torch.no_grad():\n","        outputs = model(**encodings)\n","    \n","    # Get predictions\n","    logits = outputs.logits\n","    probabilities = torch.nn.functional.softmax(logits, dim=-1)\n","    predictions = torch.argmax(probabilities, dim=-1)\n","\n","    # Convert predictions to labels\n","    label_map = {0: \"Hate Speech\", 1: \"Offensive Language\", 2: \"Neither\"}\n","    predicted_label = label_map[predictions.item()]\n","\n","    # Get confidence scores\n","    confidence_scores = probabilities.squeeze().tolist()  # convert to list of probabilities\n","\n","    return predicted_label, confidence_scores\n","\n","def main():\n","    while True:\n","        user_input = input(\"Enter a tweet to analyze (or type 'exit' to quit): \")\n","        if user_input.lower() == 'exit':\n","            break\n","        predicted_label, confidence_scores = preprocess_and_predict(user_input)\n","        print(\"Predicted label:\", predicted_label)\n","        print(\"Confidence Scores:\", confidence_scores)\n","\n","# Run the main function\n","if __name__ == \"__main__\":\n","    main()\n"]},{"cell_type":"markdown","metadata":{},"source":["## Text Cleaning Function\n","\n","This Python script uses the OpenAI API to transform potentially offensive or hate speech into polite and non-offensive language. It leverages the power of OpenAI's advanced natural language processing models to interpret and reformulate the input text.\n","\n","### Functionality\n","\n","- The script defines a function `clean_speech` that takes a string input.\n","- It sends this input to the OpenAI API, requesting a rewritten version that is non-offensive.\n","- The API's response is processed and the \"cleaned\" text is returned.\n","\n","### Usage\n","\n","1. **Input**: The user is prompted to enter a sentence that may contain offensive or hate speech.\n","2. **Processing**: The entered text is sent to the OpenAI API, which processes the text and generates a non-offensive version.\n","3. **Output**: The cleaned text is printed out.\n","\n","### Setup\n","\n","To run this script, you will need:\n","- Python installed on your machine.\n","- The `openai` Python library installed. You can install it using pip:\n","  ```bash\n","  pip install openai\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import openai\n","\n","def clean_speech(input_text):\n","    try:\n","        # Use the OpenAI API to \"translate\" offensive speech to non-offensive speech\n","        response = openai.Completion.create(\n","          engine=\"text-davinci-003\",  # You can choose a suitable model like davinci or curie\n","          prompt=f\"Rewrite the following sentence to be polite and non-offensive:\\n\\n{input_text}\",\n","          max_tokens=60  # Adjust max_tokens as necessary\n","        )\n","        return response.choices[0].text.strip()\n","    except Exception as e:\n","        return str(e)\n","\n","# Receive input from the user\n","user_input = input(\"Enter a potentially offensive sentence: \")\n","cleaned_text = clean_speech(user_input)\n","print(\"Cleaned Text:\", cleaned_text)\n"]},{"cell_type":"markdown","metadata":{},"source":["## Enhanced Text Analysis and Cleaning Function\n","\n","This updated Python script adds an integration with the OpenAI API to an existing text processing pipeline. The script classifies input text as Hate Speech, Offensive Language, or Neither and uses OpenAI's API to convert offensive content into non-offensive language.\n","\n","### Functionality\n","\n","- **Text Preprocessing and Prediction**: The input text is cleaned, tokenized, and passed through a machine learning model to classify its nature.\n","- **Integration with OpenAI API**: If the text is classified as Hate Speech or Offensive Language, it is then sent to the OpenAI API, which rewrites it to be polite and non-offensive.\n","- **Output**: The script outputs the classification label, confidence scores for each class, and, if applicable, the cleaned text.\n","\n","### Workflow\n","\n","1. **Input**: Continuously takes user input until 'exit' is entered.\n","2. **Classification and Cleaning**: Depending on the text's classification:\n","   - If offensive, it is cleaned using OpenAI.\n","   - If not offensive, the original text classification and confidence scores are output.\n","3. **Display**: Outputs the results including any cleaned text.\n","\n","### Setup and Usage\n","\n","The requirements and usage instructions are similar to the previous script, with additional conditional logic to handle text based on its classification. Ensure you have your OpenAI API key set up for this enhanced functionality.\n","\n","### Example\n","\n","Run the script, and it will prompt for input. Depending on the input's classification, it may also provide a non-offensive version of the text:\n","```python\n","python script_name.py  # replace script_name.py with your actual Python script file name\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def preprocess_and_predict(text):\n","    # Clean the text\n","    cleaned_text = clean_text(text)\n","\n","    # Tokenize the text\n","    encodings = tokenizer(cleaned_text, truncation=True, padding=True, max_length=128, return_tensors=\"pt\")\n","\n","    # Move tensors to the same device as model\n","    encodings = {key: val.to(device) for key, val in encodings.items()}\n","\n","    # Evaluation mode\n","    model.eval()\n","\n","    # Forward pass, no need to compute gradients\n","    with torch.no_grad():\n","        outputs = model(**encodings)\n","\n","    # Get predictions\n","    logits = outputs.logits\n","    probabilities = torch.nn.functional.softmax(logits, dim=-1)\n","    predictions = torch.argmax(probabilities, dim=-1)\n","\n","    # Convert predictions to labels\n","    label_map = {0: \"Hate Speech\", 1: \"Offensive Language\", 2: \"Neither\"}\n","    predicted_label = label_map[predictions.item()]\n","\n","    # Get confidence scores\n","    confidence_scores = probabilities.squeeze().tolist()  # convert to list of probabilities\n","\n","    # Check the label and process through OpenAI if necessary\n","    if predicted_label in [\"Hate Speech\", \"Offensive Language\"]:\n","        non_offensive_text = clean_speech(text)\n","        return predicted_label, confidence_scores, non_offensive_text\n","    else:\n","        return predicted_label, confidence_scores, None\n","\n","def main():\n","    while True:\n","        user_input = input(\"Enter a tweet to analyze (or type 'exit' to quit): \")\n","        if user_input.lower() == 'exit':\n","            break\n","        predicted_label, confidence_scores, cleaned_text = preprocess_and_predict(user_input)\n","        print(\"Predicted label:\", predicted_label)\n","        print(\"Confidence Scores:\", confidence_scores)\n","        if cleaned_text:\n","            print(\"Cleaned Text:\", cleaned_text)\n","\n","# Run the main function\n","if __name__ == \"__main__\":\n","    main()\n"]},{"cell_type":"markdown","metadata":{},"source":["## Text Processing and Cleanup with OpenAI\n","\n","This section of the research paper introduces two Python scripts designed to address the detection and modification of offensive or hate speech using machine learning and OpenAI's API.\n","\n","### 1. Text Cleanup Function\n","\n","This function uses OpenAI's GPT model to convert potentially offensive or hate speech into non-offensive language. It's particularly useful for moderating content or enhancing communication tools.\n","\n","#### Code Snippet\n","\n","```python\n","import openai\n","\n","def clean_speech(input_text):\n","    try:\n","        # Use the OpenAI API to \"translate\" offensive speech to non-offensive speech\n","        response = openai.Completion.create(\n","          engine=\"text-davinci-003\",  # You can choose a suitable model like davinci or curie\n","          prompt=f\"Rewrite the following sentence to be polite and non-offensive:\\n\\n{input_text}\",\n","          max_tokens=60  # Adjust max_tokens as necessary\n","        )\n","        return response.choices[0].text.strip()\n","    except Exception as e:\n","        return str(e)\n","\n","# Receive input from the user\n","user_input = input(\"Enter a potentially offensive sentence: \")\n","cleaned_text = clean_speech(user_input)\n","print(\"Cleaned Text:\", cleaned_text)\n"]},{"cell_type":"markdown","metadata":{},"source":["### 2. Text Analysis and Conditional Cleanup\n","\n","This script leverages a machine learning model to classify text into categories such as Hate Speech, Offensive Language, or Neither. If the text is determined to be offensive, it is automatically processed through the OpenAI API, which rewrites it into non-offensive language. This functionality is ideal for content moderation or enhancing communication tools in digital platforms.\n","\n","#### Code Snippet\n","\n","```python\n","def preprocess_and_predict(text):\n","    # Clean the text\n","    cleaned_text = clean_text(text)\n","\n","    # Tokenize the text\n","    encodings = tokenizer(cleaned_text, truncation=True, padding=True, max_length=128, return_tensors=\"pt\")\n","\n","    # Move tensors to the same device as model\n","    encodings = {key: val.to(device) for key, val in encodings.items()}\n","\n","    # Evaluation mode\n","    model.eval()\n","\n","    # Forward pass, no need to compute gradients\n","    with torch.no_grad():\n","        outputs = model(**encodings)\n","\n","    # Get predictions\n","    logits = outputs.logits\n","    probabilities = torch.nn.functional.softmax(logits, dim=-1)\n","    predictions = torch.argmax(probabilities, dim=-1)\n","\n","    # Convert predictions to labels\n","    label_map = {0: \"Hate Speech\", 1: \"Offensive Language\", 2: \"Neither\"}\n","    predicted_label = label_map[predictions.item()]\n","\n","    # Get confidence scores\n","    confidence_scores = probabilities.squeeze().tolist()\n","\n","    # Check the label and process through OpenAI if necessary\n","    if predicted_label in [\"Hate Speech\", \"Offensive Language\"]:\n","        non_offensive_text = clean_speech(text)\n","        return predicted_label, confidence_scores, non_offensive_text\n","    else:\n","        return predicted_label, confidence_scores, None\n","\n","def main():\n","    while True:\n","        user_input = input(\"Enter a tweet to analyze (or type 'exit' to quit): \")\n","        if user_input.lower() == 'exit':\n","            break\n","        predicted_label, confidence_scores, cleaned_text = preprocess_and_predict(user_input)\n","        print(\"Predicted label:\", predicted_label)\n","        print(\"Confidence Scores:\", confidence_scores)\n","        if cleaned_text:\n","            print(\"Cleaned Text:\", cleaned_text)\n","\n","if __name__ == \"__main__\":\n","    main()\n"]},{"cell_type":"markdown","metadata":{},"source":["## Setup and Usage\n","\n","To utilize the text cleanup and analysis functionalities provided in these scripts, follow the instructions below to ensure a smooth setup and effective usage.\n","\n","### Prerequisites\n","\n","1. **Python Installation**: Ensure Python is installed on your machine. These scripts are tested with Python 3.8 and above.\n","2. **Library Installation**:\n","    - Install the `openai` library using pip to interact with the OpenAI API:\n","      ```bash\n","      pip install openai\n","      ```\n","    - If the second script requires PyTorch and other dependencies (like a specific NLP library for tokenization and model management), install them using:\n","      ```bash\n","      pip install torch transformers\n","      ```\n","\n","3. **OpenAI API Key**:\n","    - Obtain an API key from OpenAI by registering on their platform. This key is essential for accessing the GPT model to clean offensive texts.\n","    - Configure the API key in your environment variables or directly within your script (ensure security best practices are followed if embedding directly in the script).\n","\n","### Configuration\n","\n","- Ensure the machine learning model and tokenizer are set up and configured properly for the second script:\n","  ```python\n","  from transformers import AutoModel, AutoTokenizer\n","\n","  model = AutoModel.from_pretrained(\"bert-base-uncased\")\n","  tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":4985191,"sourceId":8382690,"sourceType":"datasetVersion"}],"dockerImageVersionId":30699,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
