{"cells":[{"cell_type":"markdown","metadata":{},"source":["**Title:** BERT with Dynamic Text Cleaning using LLM\n","\n","**Summary:**\n","This notebook extends the functionality of a BERT model for text classification by incorporating dynamic text cleaning using Language Model Fine-Tuning. The primary goal is to enhance the robustness and effectiveness of the classification model by dynamically cleaning potentially offensive or harmful text inputs before prediction.\n","\n","**Key Features:**\n","1. **BERT Model for Text Classification:** The notebook utilizes a BERT (Bidirectional Encoder Representations from Transformers) model for sequence classification. BERT is a powerful pre-trained model capable of capturing contextual information in text data.\n","  \n","2. **Dynamic Text Cleaning with Language Model Fine-Tuning:** The notebook integrates OpenAI's Language Model Fine-Tuning (LLM) to dynamically clean potentially offensive or harmful text inputs before passing them to the BERT model for classification. This ensures that the model receives sanitized inputs, improving its performance and reliability.\n","\n","3. **Real-Time Text Classification:** The implemented script allows users to interactively input text for classification. The integrated text cleaning ensures that even if the input contains offensive language or hate speech, the model provides predictions based on non-offensive versions of the input text.\n","\n","4. **Enhanced Speech Processing and Prediction:** The notebook demonstrates an iterative approach to text processing and prediction, where potentially offensive inputs are automatically sanitized before classification. This enhances the usability and safety of the model for real-world applications.\n","\n","**Usage:**\n","- Users can leverage this notebook to build and deploy text classification models with enhanced robustness against offensive or harmful content.\n","- The integrated real-time text classification script allows for on-the-fly analysis of text inputs, making it suitable for applications requiring live content moderation or analysis.\n","- The combination of BERT for classification and LLM for dynamic text cleaning provides a comprehensive solution for processing user-generated content in various applications, including social media monitoring, online forums moderation, and content filtering."]},{"cell_type":"code","execution_count":2,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-05-11T09:46:15.656417Z","iopub.status.busy":"2024-05-11T09:46:15.655512Z","iopub.status.idle":"2024-05-11T09:46:15.663294Z","shell.execute_reply":"2024-05-11T09:46:15.662258Z","shell.execute_reply.started":"2024-05-11T09:46:15.656383Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Using device: cuda\n"]}],"source":["import re\n","import numpy as np\n","import pandas as pd\n","import torch\n","from torch.utils.data import DataLoader, Dataset\n","from transformers import BertTokenizer, BertForSequenceClassification, AdamW\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import classification_report, accuracy_score\n","from tqdm import tqdm\n","\n","# Check GPU availability\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(f'Using device: {device}')\n"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-05-11T09:46:19.479900Z","iopub.status.busy":"2024-05-11T09:46:19.479196Z","iopub.status.idle":"2024-05-11T09:46:19.487264Z","shell.execute_reply":"2024-05-11T09:46:19.486160Z","shell.execute_reply.started":"2024-05-11T09:46:19.479858Z"},"trusted":true},"outputs":[],"source":["emoticons = [':-)', ':)', '(:', '(-:', ':))', '((:', ':-D', ':D', 'X-D', 'XD', 'xD', 'xD', '<3', '3', ':*', ':-*', 'xP', 'XP', 'XP', 'Xp', ':-|', ':->', ':-<', '8-)', ':-P', ':-p', '=P', '=p', ':*)', '*-*', 'B-)', 'O.o', 'X-(', ')-X']\n","\n","def clean_text(text):\n","    text = text.lower()\n","    text = re.sub(r'https?://[^\\s]+', '', text)\n","    text = re.sub(r'@\\w+', '', text)\n","    text = re.sub(r'\\d+', '', text)\n","    for emoticon in emoticons:\n","        text = text.replace(emoticon, '')\n","    text = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", text)\n","    text = re.sub(r\"([?.!,¿])\", r\" \", text)\n","    text = re.sub(r'[\" \"]+', \" \", text)\n","    return text.strip()\n"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-05-11T09:46:23.331727Z","iopub.status.busy":"2024-05-11T09:46:23.331103Z","iopub.status.idle":"2024-05-11T09:46:24.224670Z","shell.execute_reply":"2024-05-11T09:46:24.223813Z","shell.execute_reply.started":"2024-05-11T09:46:23.331697Z"},"trusted":true},"outputs":[],"source":["# Load dataset\n","df = pd.read_csv('/kaggle/input/dataset/labeled_data.csv')\n","df['tweet'] = df['tweet'].apply(clean_text)\n","\n","# Split dataset\n","train_texts, temp_texts, train_labels, temp_labels = train_test_split(df['tweet'], df['class'], test_size=0.3, random_state=42)\n","val_texts, test_texts, val_labels, test_labels = train_test_split(temp_texts, temp_labels, test_size=0.5, random_state=42)\n"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-05-11T09:46:27.033936Z","iopub.status.busy":"2024-05-11T09:46:27.033566Z","iopub.status.idle":"2024-05-11T09:46:41.347139Z","shell.execute_reply":"2024-05-11T09:46:41.346318Z","shell.execute_reply.started":"2024-05-11T09:46:27.033905Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7a6db0fb0b1d4ebb9f4f2340c2f4f775","version_major":2,"version_minor":0},"text/plain":["tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0556dcb5a91c452ab4a31d13cf0881ee","version_major":2,"version_minor":0},"text/plain":["vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"272f12522d154d40bcfa1f3cbbb353b1","version_major":2,"version_minor":0},"text/plain":["tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6b99e8b7be3d46a8928b7549a51747a0","version_major":2,"version_minor":0},"text/plain":["config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"}],"source":["tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n","\n","train_encodings = tokenizer(train_texts.tolist(), truncation=True, padding=True, max_length=128)\n","test_encodings = tokenizer(test_texts.tolist(), truncation=True, padding=True, max_length=128)\n","val_encodings = tokenizer(val_texts.tolist(), truncation=True, padding=True, max_length=128)\n"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-05-11T09:46:44.739692Z","iopub.status.busy":"2024-05-11T09:46:44.739038Z","iopub.status.idle":"2024-05-11T09:46:44.747666Z","shell.execute_reply":"2024-05-11T09:46:44.746100Z","shell.execute_reply.started":"2024-05-11T09:46:44.739660Z"},"trusted":true},"outputs":[],"source":["# Dataset class\n","class TweetDataset(Dataset):\n","    def __init__(self, encodings, labels):\n","        self.encodings = encodings\n","        self.labels = labels\n","\n","    def __getitem__(self, idx):\n","        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n","        item['labels'] = torch.tensor(self.labels[idx])\n","        return item\n","\n","    def __len__(self):\n","        return len(self.labels)\n","\n","train_dataset = TweetDataset(train_encodings, train_labels.tolist())\n","test_dataset = TweetDataset(test_encodings, test_labels.tolist())\n","val_dataset = TweetDataset(val_encodings, val_labels.tolist())"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-05-11T09:46:48.633599Z","iopub.status.busy":"2024-05-11T09:46:48.633242Z","iopub.status.idle":"2024-05-11T09:46:48.638968Z","shell.execute_reply":"2024-05-11T09:46:48.637861Z","shell.execute_reply.started":"2024-05-11T09:46:48.633569Z"},"trusted":true},"outputs":[],"source":["batch_size = 32\n","\n","train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n","val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n","test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-05-11T09:46:51.094292Z","iopub.status.busy":"2024-05-11T09:46:51.093619Z","iopub.status.idle":"2024-05-11T09:46:53.482559Z","shell.execute_reply":"2024-05-11T09:46:53.481771Z","shell.execute_reply.started":"2024-05-11T09:46:51.094260Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"decd022421254646bece36d2ba7f868d","version_major":2,"version_minor":0},"text/plain":["model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/opt/conda/lib/python3.10/site-packages/transformers/optimization.py:457: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n"]}],"source":["# Model initialization\n","model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=3)\n","optimizer = AdamW(model.parameters(), lr=5e-6)\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","model.to(device)\n","\n","# Training function\n","def train(epoch):\n","    model.train()\n","    total_loss, total_accuracy = 0, 0\n","    for batch in tqdm(train_loader, desc=f\"Training Epoch {epoch}\"):\n","        optimizer.zero_grad()\n","        input_ids = batch['input_ids'].to(device)\n","        attention_mask = batch['attention_mask'].to(device)\n","        labels = batch['labels'].to(device)\n","        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n","        loss = outputs.loss\n","        loss.backward()\n","        optimizer.step()\n","        \n","        total_loss += loss.item()\n","        logits = outputs.logits.detach().cpu().numpy()\n","        predictions = np.argmax(logits, axis=-1)\n","        total_accuracy += accuracy_score(labels.cpu().numpy(), predictions)\n","    \n","    avg_loss = total_loss / len(train_loader)\n","    avg_accuracy = total_accuracy / len(train_loader)\n","    print(f\"Training Loss: {avg_loss:.3f}\")\n","    print(f\"Training Accuracy: {avg_accuracy:.3f}\")"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-05-11T09:46:57.063532Z","iopub.status.busy":"2024-05-11T09:46:57.063197Z","iopub.status.idle":"2024-05-11T09:46:57.072752Z","shell.execute_reply":"2024-05-11T09:46:57.071638Z","shell.execute_reply.started":"2024-05-11T09:46:57.063506Z"},"trusted":true},"outputs":[],"source":["# Evaluation function\n","def evaluate(loader, desc=\"Evaluating\"):\n","    model.eval()\n","    total_loss, total_accuracy = 0, 0\n","    all_predictions, all_labels = [], []\n","    \n","    for batch in tqdm(loader, desc=desc):\n","        input_ids = batch['input_ids'].to(device)\n","        attention_mask = batch['attention_mask'].to(device)\n","        labels = batch['labels'].to(device)\n","        with torch.no_grad():\n","            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n","        \n","        loss = outputs.loss.item()\n","        total_loss += loss\n","        logits = outputs.logits.detach().cpu().numpy()\n","        predictions = np.argmax(logits, axis=-1)\n","        total_accuracy += accuracy_score(labels.cpu().numpy(), predictions)\n","        \n","        all_predictions.extend(predictions)\n","        all_labels.extend(labels.cpu().numpy())\n","\n","    avg_loss = total_loss / len(loader)\n","    avg_accuracy = total_accuracy / len(loader)\n","    print(f\"Validation Loss: {avg_loss:.3f}\")\n","    print(f\"Validation Accuracy: {avg_accuracy:.3f}\")\n","    \n","    return all_labels, all_predictions"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2024-05-11T09:47:00.509166Z","iopub.status.busy":"2024-05-11T09:47:00.508442Z","iopub.status.idle":"2024-05-11T09:51:58.414522Z","shell.execute_reply":"2024-05-11T09:51:58.413630Z","shell.execute_reply.started":"2024-05-11T09:47:00.509125Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Training Epoch 1: 100%|██████████| 543/543 [01:31<00:00,  5.94it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Training Loss: 0.445\n","Training Accuracy: 0.854\n"]},{"name":"stderr","output_type":"stream","text":["Evaluating: 100%|██████████| 117/117 [00:06<00:00, 18.82it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Validation Loss: 0.301\n","Validation Accuracy: 0.902\n"]},{"name":"stderr","output_type":"stream","text":["Training Epoch 2: 100%|██████████| 543/543 [01:30<00:00,  5.98it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Training Loss: 0.259\n","Training Accuracy: 0.912\n"]},{"name":"stderr","output_type":"stream","text":["Evaluating: 100%|██████████| 117/117 [00:06<00:00, 18.61it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Validation Loss: 0.252\n","Validation Accuracy: 0.914\n"]},{"name":"stderr","output_type":"stream","text":["Training Epoch 3: 100%|██████████| 543/543 [01:30<00:00,  5.98it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Training Loss: 0.224\n","Training Accuracy: 0.922\n"]},{"name":"stderr","output_type":"stream","text":["Evaluating: 100%|██████████| 117/117 [00:06<00:00, 18.65it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Validation Loss: 0.256\n","Validation Accuracy: 0.913\n"]},{"name":"stderr","output_type":"stream","text":["Final Test Evaluation: 100%|██████████| 117/117 [00:06<00:00, 19.35it/s]"]},{"name":"stdout","output_type":"stream","text":["Validation Loss: 0.245\n","Validation Accuracy: 0.911\n","                    precision    recall  f1-score   support\n","\n","       Hate Speech       0.46      0.50      0.48       207\n","Offensive Language       0.95      0.94      0.94      2880\n","           Neither       0.88      0.91      0.90       631\n","\n","          accuracy                           0.91      3718\n","         macro avg       0.77      0.78      0.78      3718\n","      weighted avg       0.91      0.91      0.91      3718\n","\n","Test Accuracy: 0.910\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["# Main training loop\n","for epoch in range(1, 4):\n","    train(epoch)\n","    evaluate(val_loader)\n","\n","# Final evaluation on test set\n","labels, predictions = evaluate(test_loader, \"Final Test Evaluation\")\n","print(classification_report(labels, predictions, target_names=['Hate Speech', 'Offensive Language', 'Neither']))\n","\n","# Accuracy\n","accuracy = accuracy_score(labels, predictions)\n","print(f\"Test Accuracy: {accuracy:.3f}\")"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2024-05-11T09:52:07.719448Z","iopub.status.busy":"2024-05-11T09:52:07.718766Z","iopub.status.idle":"2024-05-11T09:52:07.773793Z","shell.execute_reply":"2024-05-11T09:52:07.772927Z","shell.execute_reply.started":"2024-05-11T09:52:07.719418Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Number of hate speech comments: 1430\n","Examples of hate speech comments:\n","                                                 tweet\n","85   \"@Blackman38Tide: @WhaleLookyHere @HowdyDowdy1...\n","89   \"@CB_Baby24: @white_thunduh alsarabsss\" hes a ...\n","110  \"@DevilGrimz: @VigxRArts you're fucking gay, b...\n","184  \"@MarkRoundtreeJr: LMFAOOOO I HATE BLACK PEOPL...\n","202  \"@NoChillPaz: \"At least I'm not a nigger\" http...\n"]}],"source":["import pandas as pd\n","\n","# Load the dataset (replace 'path_to_your_dataset.csv' with your actual dataset path)\n","df = pd.read_csv('/kaggle/input/dataset/labeled_data.csv')\n","\n","# Filter the dataset for hate speech comments\n","hate_speech_comments = df[df['class'] == 0]\n","\n","# Display the hate speech comments\n","print(\"Number of hate speech comments:\", hate_speech_comments.shape[0])\n","print(\"Examples of hate speech comments:\")\n","print(hate_speech_comments[['tweet']].head())  # Display the first few comments\n"]},{"cell_type":"markdown","metadata":{},"source":["## Real-Time Text Classification Script\n","\n","This Python script is designed to classify text inputs in real-time, making it an invaluable tool for monitoring and analyzing user-generated content live. It can identify if the text is hate speech, offensive language, or neither.\n","\n","### Script Overview\n","\n","The script engages with the user in an interactive session where it continuously accepts text inputs. Each input is processed to determine its classification based on predefined categories: Hate Speech, Offensive Language, or Neither. This is particularly useful for applications that require live moderation or instant text analysis.\n","\n","### Code Functionality\n","\n","- **Text Cleaning**: Initially, the text provided by the user is cleaned to remove any unwanted characters or formatting.\n","- **Text Tokenization and Encoding**: The cleaned text is tokenized and encoded using a pre-configured tokenizer and model setup.\n","- **Model Prediction**: The tokenized text is fed into a neural network model, which evaluates the text and produces a prediction.\n","- **Classification**: The output from the model is interpreted as one of the three categories based on the highest probability.\n","- **Confidence Scores**: Alongside the classification, the script also outputs the confidence scores for each category, providing insight into the model's decision-making process.\n"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2024-05-11T09:52:11.643706Z","iopub.status.busy":"2024-05-11T09:52:11.642799Z","iopub.status.idle":"2024-05-11T09:54:13.288533Z","shell.execute_reply":"2024-05-11T09:54:13.287760Z","shell.execute_reply.started":"2024-05-11T09:52:11.643662Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Enter a tweet to analyze (or type 'exit' to quit):  \"@BlackChiquitita: Wow. RT @thatmanpalmer I'm lost. Are those buttcheek piercings? http://t.co/yn6guyOUQ6\" yeah she's a hoe\n"]},{"name":"stdout","output_type":"stream","text":["Predicted label: Offensive Language\n","Confidence Scores: [0.006117755081504583, 0.9910361766815186, 0.0028460542671382427]\n"]},{"name":"stdout","output_type":"stream","text":["Enter a tweet to analyze (or type 'exit' to quit):  I Love You\n"]},{"name":"stdout","output_type":"stream","text":["Predicted label: Neither\n","Confidence Scores: [0.04179545119404793, 0.03325523063540459, 0.9249493479728699]\n"]},{"name":"stdout","output_type":"stream","text":["Enter a tweet to analyze (or type 'exit' to quit):  Yor are an Idiot \n"]},{"name":"stdout","output_type":"stream","text":["Predicted label: Offensive Language\n","Confidence Scores: [0.37119174003601074, 0.5972275733947754, 0.03158074989914894]\n"]},{"name":"stdout","output_type":"stream","text":["Enter a tweet to analyze (or type 'exit' to quit):  exit\n"]}],"source":["def preprocess_and_predict(text):\n","    # Clean the text\n","    cleaned_text = clean_text(text)\n","\n","    # Tokenize the text\n","    encodings = tokenizer(cleaned_text, truncation=True, padding=True, max_length=128, return_tensors=\"pt\")\n","\n","    # Move tensors to the same device as model\n","    encodings = {key: val.to(device) for key, val in encodings.items()}\n","\n","    # Evaluation mode\n","    model.eval()\n","\n","    # Forward pass, no need to compute gradients\n","    with torch.no_grad():\n","        outputs = model(**encodings)\n","    \n","    # Get predictions\n","    logits = outputs.logits\n","    probabilities = torch.nn.functional.softmax(logits, dim=-1)\n","    predictions = torch.argmax(probabilities, dim=-1)\n","\n","    # Convert predictions to labels\n","    label_map = {0: \"Hate Speech\", 1: \"Offensive Language\", 2: \"Neither\"}\n","    predicted_label = label_map[predictions.item()]\n","\n","    # Get confidence scores\n","    confidence_scores = probabilities.squeeze().tolist()  # convert to list of probabilities\n","\n","    return predicted_label, confidence_scores\n","\n","def main():\n","    while True:\n","        user_input = input(\"Enter a tweet to analyze (or type 'exit' to quit): \")\n","        if user_input.lower() == 'exit':\n","            break\n","        predicted_label, confidence_scores = preprocess_and_predict(user_input)\n","        print(\"Predicted label:\", predicted_label)\n","        print(\"Confidence Scores:\", confidence_scores)\n","\n","# Run the main function\n","if __name__ == \"__main__\":\n","    main()\n"]},{"cell_type":"markdown","metadata":{},"source":["## Cleaning Offensive Speech with OpenAI API\n","\n","This section of the notebook demonstrates how to use the OpenAI API to transform potentially offensive or hate speech into a non-offensive format. The provided function `clean_speech` uses the OpenAI API to make requests to the model specified (in this case, `text-davinci-003`) to rewrite the input text.\n","\n","### Functionality\n","The `clean_speech` function takes an input string which may contain offensive content and rewrites it to ensure that the content is polite and non-offensive. This is particularly useful in moderating content in applications where user-generated content needs to be sanitized for public viewing or further analysis.\n","\n","### Usage\n","To use this function, provide a string input to the `clean_speech` function. The function sends this text to the OpenAI API and receives a modified version of the text that is free from offensive content.\n","\n","### Example\n","Here is how you can use the `clean_speech` function:\n","```python\n","input_text = \"Your example text here\"\n","cleaned_text = clean_speech(input_text)\n","print(\"Cleaned Text:\", cleaned_text)\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import openai\n","\n","def clean_speech(input_text):\n","    \"\"\"\n","    This function takes a potentially offensive input text and uses OpenAI's API to generate a non-offensive version.\n","    \"\"\"\n","    try:\n","        response = openai.Completion.create(\n","            model=\"text-davinci-003\",  # Using a capable model for content moderation and rewriting\n","            prompt=f\"Rewrite the following to be polite and non-offensive: {input_text}\",\n","            max_tokens=100,\n","            temperature=0.7\n","        )\n","        return response.choices[0].text.strip()\n","    except Exception as e:\n","        return f\"Error processing the input: {str(e)}\"\n","\n","# Example usage\n","input_text = \"Your input text here\"\n","cleaned_text = clean_speech(input_text)\n","print(\"Cleaned Text:\", cleaned_text)\n"]},{"cell_type":"markdown","metadata":{},"source":["## Enhanced Speech Processing and Prediction with OpenAI API\n","\n","This section of the notebook extends our previous text processing functionalities by integrating OpenAI's API to transform any identified hate or offensive speech into a non-offensive format, enhancing the usability and safety of the content.\n","\n","### Enhanced Functionality\n","The `preprocess_and_predict` function now includes an additional step where any text classified as \"Hate Speech\" or \"Offensive Language\" is automatically rewritten to be non-offensive using the OpenAI API. This ensures that all outputs from our model adhere to community standards and are suitable for public display.\n","\n","### How It Works\n","1. Text is first cleaned and tokenized.\n","2. The model predicts whether the text is hate speech, offensive, or neither.\n","3. If the text is classified as hate speech or offensive, it is sent to the OpenAI API to be rewritten.\n","4. The final output includes the label, confidence scores, and the processed text.\n","\n","### Running the Code\n","You can run this processing loop by invoking the `main` function. It allows continuous input and processing of text until 'exit' is entered. Here's an example of how it works:\n","```python\n","# This will start the input loop, allowing you to test live predictions and rewrites.\n","if __name__ == \"__main__\":\n","    main()\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import torch\n","import openai\n","\n","def preprocess_and_predict(text):\n","    # Clean the text\n","    cleaned_text = clean_text(text)\n","\n","    # Tokenize the text\n","    encodings = tokenizer(cleaned_text, truncation=True, padding=True, max_length=128, return_tensors=\"pt\")\n","\n","    # Move tensors to the same device as model\n","    encodings = {key: val.to(device) for key, val in encodings.items()}\n","\n","    # Evaluation mode\n","    model.eval()\n","\n","    # Forward pass, no need to compute gradients\n","    with torch.no_grad():\n","        outputs = model(**encodings)\n","    \n","    # Get predictions\n","    logits = outputs.logits\n","    probabilities = torch.nn.functional.softmax(logits, dim=-1)\n","    predictions = torch.argmax(probabilities, dim=-1)\n","\n","    # Convert predictions to labels\n","    label_map = {0: \"Hate Speech\", 1: \"Offensive Language\", 2: \"Neither\"}\n","    predicted_label = label_map[predictions.item()]\n","\n","    # Get confidence scores\n","    confidence_scores = probabilities.squeeze().tolist()  # convert to list of probabilities\n","\n","    # Check if the predicted label is offensive or hate speech\n","    if predicted_label in [\"Hate Speech\", \"Offensive Language\"]:\n","        cleaned_text = clean_speech(cleaned_text)\n","\n","    return predicted_label, confidence_scores, cleaned_text\n","\n","def main():\n","    while True:\n","        user_input = input(\"Enter a tweet to analyze (or type 'exit' to quit): \")\n","        if user_input.lower() == 'exit':\n","            break\n","        predicted_label, confidence_scores, cleaned_text = preprocess_and_predict(user_input)\n","        print(\"Predicted label:\", predicted_label)\n","        print(\"Confidence Scores:\", confidence_scores)\n","        print(\"Processed Text:\", cleaned_text)\n","\n","# Run the main function\n","if __name__ == \"__main__\":\n","    main()\n"]},{"cell_type":"markdown","metadata":{},"source":["## Integrating OpenAI for Content Moderation\n","\n","This repository includes two conceptual Python code snippets designed to demonstrate how to use OpenAI's API to transform offensive or potentially harmful speech into non-offensive and more acceptable content. These code snippets are provided for educational and developmental purposes, and they can be implemented by users with access to OpenAI's API.\n","\n","### 1. Text Cleaning Function\n","\n","#### Description\n","The `clean_speech` function takes an input string that may contain offensive content and uses the OpenAI API to generate a non-offensive version of the text. This function is designed to be a simple, plug-and-play solution for content moderation tasks.\n","\n","#### Code Snippet\n","```python\n","import openai\n","\n","def clean_speech(input_text):\n","    \"\"\"\n","    Takes potentially offensive input text and uses OpenAI's API to generate a non-offensive version.\n","    \"\"\"\n","    try:\n","        response = openai.Completion.create(\n","            model=\"text-davinci-003\",\n","            prompt=f\"Rewrite the following to be polite and non-offensive: {input_text}\",\n","            max_tokens=100,\n","            temperature=0.7\n","        )\n","        return response.choices[0].text.strip()\n","    except Exception as e:\n","        return f\"Error processing the input: {str(e)}\"\n","\n","# Example usage\n","input_text = \"Your input text here\"\n","cleaned_text = clean_speech(input_text)\n","print(\"Cleaned Text:\", cleaned_text)\n"]},{"cell_type":"markdown","metadata":{},"source":["### 2. Speech Processing and Prediction\n","\n","#### Description\n","The `preprocess_and_predict` function integrates several steps: cleaning text, tokenizing, predicting using a machine learning model, and conditionally transforming text based on the classification results. If the text is identified as hate speech or offensive language, it is automatically rewritten to be non-offensive using the OpenAI API. This function is ideal for applications needing automated content moderation in real-time.\n","\n","#### Code Snippet\n","```python\n","import torch\n","import openai\n","\n","def preprocess_and_predict(text):\n","    # Initial text cleaning\n","    cleaned_text = clean_text(text)\n","\n","    # Text tokenization\n","    encodings = tokenizer(cleaned_text, truncation=True, padding=True, max_length=128, return_tensors=\"pt\")\n","\n","    # Model preparation and prediction\n","    encodings = {key: val.to(device) for key, val in encodings.items()}\n","    model.eval()\n","    with torch.no_grad():\n","        outputs = model(**encodings)\n","    logits = outputs.logits\n","    probabilities = torch.nn.functional.softmax(logits, dim=-1)\n","    predictions = torch.argmax(probabilities, dim=-1)\n","    predicted_label = {0: \"Hate Speech\", 1: \"Offensive Language\", 2: \"Neither\"}[predictions.item()]\n","\n","    # Post-prediction text processing\n","    if predicted_label in [\"Hate Speech\", \"Offensive Language\"]:\n","        cleaned_text = clean_speech(cleaned_text)\n","\n","    confidence_scores = probabilities.squeeze().tolist()\n","    return predicted_label, confidence_scores, cleaned_text\n","\n","def main():\n","    while True:\n","        user_input = input(\"Enter a tweet to analyze (or type 'exit' to quit): \")\n","        if user_input.lower() == 'exit':\n","            break\n","        predicted_label, confidence_scores, cleaned_text = preprocess_and_predict(user_input)\n","        print(\"Predicted label:\", predicted_label)\n","        print(\"Confidence Scores:\", confidence_scores)\n","        print(\"Processed Text:\", cleaned_text)\n","\n","# To run the main function\n","if __name__ == \"__main__\":\n","    main()\n"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":4985191,"sourceId":8382690,"sourceType":"datasetVersion"}],"dockerImageVersionId":30699,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
